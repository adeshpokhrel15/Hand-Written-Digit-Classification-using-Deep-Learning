# -*- coding: utf-8 -*-
"""Hand Written Digit Classification using Deep Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vy5Jtcg9LXlP-X8i6ABaABVMAqeuTK-B
"""

#Importing the Library
import tensorflow as tf
import matplotlib.pyplot as plt

mnist=tf.keras.datasets.mnist  #Loading the data from Mnist Dataset

#Here X is a image and y is its label
(X_train,y_train),(X_test,y_test)=mnist.load_data()   #Automatically split data in 70%-30% in train-test respectively

X_train

X_train=tf.keras.utils.normalize(X_train,axis=1)  #Feature Scaling using Normalization method #axis=1 is for columns
X_test=tf.keras.utils.normalize(X_test,axis=1)

X_train[0] #Every featured is scaled down between 0 and 1

#Lets take model

model=tf.keras.models.Sequential()  ##a feed forward model
model.add(tf.keras.layers.Flatten()) #takes our 28x28 and makes it 1x784
model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))  #connected layers
model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))
model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))

model.compile(optimizer='adam',
               loss='sparse_categorical_crossentropy', #how will we calculate the error to minimize the loss
              metrics=['accuracy'])

model.fit(X_train,y_train,epochs=10)

#Lets check the loss and accuracy
loss,accuracy=model.evaluate(X_test,y_test)

loss

accuracy

#Lets predict now
X_test[50]

#showing the predicted value in figure
plt.imshow(X_test[50],cmap=plt.cm.binary)
plt.show()



